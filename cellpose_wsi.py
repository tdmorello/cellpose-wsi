# -*- coding: utf-8 -*-
"""cellpose_wsi_segmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j2glgQfxJyIM4YZRwbyerotGHXrn697k
"""

import json
import os
from pathlib import Path

import bioformats
import cv2
import geopandas as gpd
import javabridge
import numpy as np
from cellpose import models
from shapely.geometry import Polygon
from shapely.strtree import STRtree
from tiler import Tiler
from tqdm.notebook import tqdm

javabridge.start_vm(class_path=bioformats.JARS)

use_GPU = models.use_gpu()
print('>>> GPU activated? %d' % use_GPU)

filename = "/content/gdrive/MyDrive/image-processing/b38f-sag_L-neun_calr-w11_2-cla-63x-a_overview.czi"
filename = Path(filename)

input_folder = "/content/gdrive/MyDrive/image-processing/"
img_extension = "czi"

files_list = []

# # r=root, d=directories, f = files
files = []
recursive_search = False
for r, d, f in os.walk(input_folder):
    for fil in f:
        if (img_extension):
            if fil.endswith(img_extension):
                files.append(os.path.join(r, fil))
        else:
            files.append(os.path.join(r, fil))
    if recursive_search:
        continue
    else:
        break

print(f'found {len(files)} files')

downsample = 2
tile_size = 2048

model_type = "cyto"
diameter = 40
segment_channel = 1
nuclear_channel = 2

channels = [segment_channel, nuclear_channel]
model = models.Cellpose(gpu=use_GPU, model_type=model_type)

# Read files, preprocess, and load into array for cellpose
print(f'Reading image {str(filename)}')
reader = bioformats.ImageReader(str(filename))


def reader_func(*args) -> np.ndarray:
    X, Y, W, H = args[0], args[1], args[3], args[4]
    return reader.read(XYWH=(X, Y, W, H))  # type: ignore


sizeX, sizeY, sizeC = (reader.rdr.getSizeX(),
                       reader.rdr.getSizeY(), reader.rdr.getSizeC())
tiler = Tiler((sizeX, sizeY, sizeC),
              (tile_size, tile_size, sizeC), overlap=0.05)


def preprocess(img):
    img = cv2.resize(img, (0, 0), fx=1/downsample, fy=1/downsample)
    img = cv2.medianBlur(img, 3)
    return img


print('Loading and processing tiles')
imgs = []
for i, img in tqdm(tiler.iterate(reader_func), total=len(tiler)):
    imgs.append(preprocess(img))

masks, flows, styles, diams = model.eval(
    imgs, diameter=diameter, channels=channels)

# Process shapes
print('Converting masks to shapes')
geoms = []
for tile_idx, mask in tqdm(enumerate(masks), total=len(masks)):
    x_offset, y_offset, _ = tiler.get_tile_bbox_position(tile_idx)[0]
    for i in range(mask.max()):
        m = (mask == i+1).astype(np.uint8)
        c, hier = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
        c = max(c, key=cv2.contourArea).squeeze()
        c[:, 0] = c[:, 0] + x_offset/downsample
        c[:, 1] = c[:, 1] + y_offset/downsample

        new_poly = Polygon(c)
        # Try to fix invalid geoms
        if new_poly.is_valid:
            geoms.append(new_poly)
        else:
            geoms.append(new_poly.buffer(0))

# an auxiliary dictionary to get the original indices
# https://shapely.readthedocs.io/en/stable/manual.html#strtree.STRtree.strtree.query
index_by_id = dict((id(pt), i) for i, pt in enumerate(geoms))

filtered = []
# Remove fractured edge detections
tree = STRtree(geoms)
for geom in tqdm(geoms):
    hits = [hit for hit in tree.query(geom) if geom.intersects(hit)]
    if len(hits) == 1:
        idx = 0
    elif len(hits) > 1:
        areas = [h.area for h in hits]
        idx = areas.index(max(areas))
    else:
        continue

    filtered.append(index_by_id[id(hits[idx])])
    filtered_geoms = [geoms[idx] for idx in filtered]

# Rescale shapes
geom_series = gpd.GeoSeries(filtered_geoms).scale(  # type: ignore
    xfact=downsample, yfact=downsample, origin=(0, 0))
geo_df = gpd.GeoDataFrame({'geometry': geom_series})

# Save shapes to json in geojson format
with open(filename.parent / (filename.stem + '-CP_detections.json'), 'w') as f:
    # test geopandas to dict, then to json
    json_obj = json.loads(geo_df.to_json())['features']
    for entry in json_obj:
        entry['id'] = 'PathDetectionObject'
    f.write(json.dumps(json_obj))
